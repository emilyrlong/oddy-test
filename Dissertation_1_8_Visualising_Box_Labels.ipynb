{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Dissertation 1.8: Visualising Box Labels",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vPs64QA1Zdov",
        "21tUtyyVrkIt",
        "tcPfo571mnzz",
        "CzeV2O4Szj2W",
        "yVeDQaSdrkJC",
        "IogyryF2lFBL",
        "HyzSGUDsrkI7",
        "Dqb_yjAo3cO_",
        "VTvj7Q0oYk75",
        "HwAi3yImUYln",
        "EdfVgnDYUgvN",
        "0k6oFoxTrkJi",
        "K-GIbqkzrkJ_",
        "UpKOWo_iPCPy",
        "JsuwRvzAQEzd",
        "OWK2GfENUgVJ",
        "CLNCs-hEbeiF",
        "haj4h5IGdTai"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyrlong/oddy-test/blob/main/Dissertation_1_8_Visualising_Box_Labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Dissertation: Visualising the Box Labels\n",
        "\n",
        "Using the trained models to plot predictions of box labels on images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m35sE9VxMfbf"
      },
      "source": [
        "# Connect colab to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## **Step 1**: Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxXN6EYMKFZ"
      },
      "source": [
        "# !pip install tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZYLovMlYNp6"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMNX7lKR0fk1"
      },
      "source": [
        "#!pip install tensorflow-gpu\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mGaSh9sYWg1"
      },
      "source": [
        "# Testing whether or not we're on a high memory RAM\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-J7whqrkIl"
      },
      "source": [
        "Install the Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi28cqGGFWnY"
      },
      "source": [
        "# uncomment the next line if you want to delete an existing models directory\n",
        "!rm -rf ./models/\n",
        "\n",
        "# clone the Tensorflow Model Garden\n",
        "!git clone --depth 1 https://github.com/tensorflow/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwdsBdGhFanc"
      },
      "source": [
        "# install the Object Detection API\n",
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "## **Step 2**: Import Packages\n",
        "\n",
        "Let's now import the packages you will use in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW7YShaj2iXN"
      },
      "source": [
        "!pip install dfply\n",
        "from dfply import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-auwvBQrkIw"
      },
      "source": [
        "### **Step 2.1**: Import Object Detection API packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YihOFxxrkIw"
      },
      "source": [
        "### START CODE HERE (Replace Instances of `None` with your code) ###\n",
        "# import the label map utility module\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# import module for reading and updating configuration files.\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "# import module for visualization. use the alias `viz_utils`\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# import module for building the detection model\n",
        "from object_detection.builders import model_builder\n",
        "### END CODE HERE ###\n",
        "\n",
        "# import module for utilities in Colab\n",
        "from object_detection.utils import colab_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyn1KvhRHTSz"
      },
      "source": [
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcPfo571mnzz"
      },
      "source": [
        "## **Step 3**: Import and Clean Label Data\n",
        "The labeller MakeSense.ai outputted (xmin, ymin, xdiff, ydiff) where xdiff and ydiff are equal to the difference between the minimum and maximum coordinates, so we need to make some new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOf3xCKvmm_b"
      },
      "source": [
        "# Load in the csv from the labels folder in drive\n",
        "label_df = pd.read_csv('/content/drive/MyDrive/Dissertation/labels/Fulldata_Aug12.csv')\n",
        "# label_df = pd.read_csv('/content/drive/MyDrive/Dissertation/labels/UnanimousAug22.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA6krYHtnSTl"
      },
      "source": [
        "label_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzeV2O4Szj2W"
      },
      "source": [
        "### **Step 3.1**: Getting Integer Class Values\n",
        "We need to make a column with the mapped integer values for the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCjMj0_OsR7n"
      },
      "source": [
        "# Load label map from file\n",
        "# Function found here: https://github.com/tensorflow/models/blob/master/research/object_detection/utils/label_map_util.py\n",
        "label_map = label_map_util.load_labelmap('/content/drive/MyDrive/Dissertation/labels/StringIntLabelMap.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnY4YTNx6JA"
      },
      "source": [
        "# Convert to dictionary\n",
        "label_dict = label_map_util.get_label_map_dict(label_map,use_display_name=True)\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgu1JEZVzRzx"
      },
      "source": [
        "# Map the label dictionary to a column to populate the corresponding class integer values\n",
        "# https://kanoki.org/2019/04/06/pandas-map-dictionary-values-with-dataframe-columns/\n",
        "label_df['classInt'] = label_df['class'].map(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVeDQaSdrkJC"
      },
      "source": [
        "### **Step 3.2**: Define the category index dictionary + NumClasses\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWBqFVMcweF-"
      },
      "source": [
        "# define a dictionary describing the corrosion classes\n",
        "category_index = {\n",
        "    1 : {\n",
        "        'id'  : 1, \n",
        "        'name': 'Ag-P'\n",
        "    },\n",
        "    2 : {\n",
        "        'id'  : 2,\n",
        "        'name': 'Ag-T'\n",
        "    },\n",
        "    3 : {\n",
        "        'id'  : 3,\n",
        "        'name': 'Ag-U'\n",
        "    },\n",
        "    4 : {\n",
        "        'id'  : 4,\n",
        "        'name': 'Cu-P'\n",
        "    },\n",
        "    5 : {\n",
        "        'id'  : 5,\n",
        "        'name': 'Cu-T'\n",
        "    },\n",
        "    6 : {\n",
        "        'id'  : 6,\n",
        "        'name': 'Cu-U'\n",
        "    },\n",
        "    7 : {\n",
        "        'id'  : 7,\n",
        "        'name': 'Pb-P'\n",
        "    },\n",
        "    8 : {\n",
        "        'id'  : 8,\n",
        "        'name': 'Pb-T'\n",
        "    },\n",
        "    9 : {\n",
        "        'id'  : 9,\n",
        "        'name': 'Pb-U'\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPy7vfCCrkJF"
      },
      "source": [
        "# Testing grabbing the categories\n",
        "print(category_index[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOkztZ0-Fytp"
      },
      "source": [
        "# Specify the number of classes that the model will predict\n",
        "num_classes = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogyryF2lFBL"
      },
      "source": [
        "## **Step 4**: Defining Functions\n",
        "\n",
        "You'll define a couple of utility functions for loading images and plotting detections. This code is provided for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRAEdg1AJGtX"
      },
      "source": [
        "### **Function 1**: `plot_detections`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMNWCNIaFYoV"
      },
      "source": [
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "    \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "    Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "          and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "          this function assumes that the boxes to be plotted are groundtruth\n",
        "          boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "          category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "    \"\"\"\n",
        "    \n",
        "    image_np_with_annotations = image_np.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_annotations,\n",
        "        boxes,\n",
        "        classes,\n",
        "        scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=10,\n",
        "        min_score_thresh=0.3,\n",
        "        line_thickness = 10)\n",
        "    \n",
        "    if image_name:\n",
        "        plt.imsave(image_name, image_np_with_annotations)\n",
        "    \n",
        "    else:\n",
        "        plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyzSGUDsrkI7"
      },
      "source": [
        "### **Function 2**: `load_npy_set`\n",
        "\n",
        "Get the training images from the Google Drive folder and their file names. The images are quite large, so the step which converts them into numpy arrays will take a while.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0m3IESntTsu"
      },
      "source": [
        "# A FUNCTION FOR LOADING IMAGES\n",
        "def load_npy_set(npy_dir):\n",
        "    \"\"\"Load a folder of numpy arrays corresponding to images.\n",
        "    Args: npy_dir - a path to folder of training, validation, or test images. \n",
        "    Returns: images_np - a list of the numpy array versions of the images\n",
        "    \"\"\"\n",
        "    # Getting list of npy files\n",
        "    files = os.listdir(npy_dir)\n",
        "    # Starting an empty list for the npy arrays\n",
        "    images_np = []\n",
        "    # For loop to add each file (npy array) to the image list\n",
        "    for idx, file in enumerate(files):\n",
        "      npy_path = os.path.join(npy_dir,file)\n",
        "      test_img = np.load(npy_path)\n",
        "      images_np.append(test_img)\n",
        "      if idx % 10 == 0:\n",
        "        print('Loading',str(idx),':',file)\n",
        "    # When finished, print message and return \n",
        "    print('Done Loading!')\n",
        "    return images_np, files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqb_yjAo3cO_"
      },
      "source": [
        "### **Function 3**: `box_lister`\n",
        "Converting the box coordinates and class labels into a list of numpy arrays. These can be visualised on top of the images and further converted into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_pzwo4eHSG2"
      },
      "source": [
        "def box_lister(files):\n",
        "    # Define a list of ground truth boxes\n",
        "    gt_boxes = []\n",
        "    # Define a list of class integers\n",
        "    classes = []\n",
        "    # For loop to iterate over the file names\n",
        "    for file in files:\n",
        "      # Need to change 'npy' extension to 'jpg'\n",
        "      file = file.replace('npy','jpg')\n",
        "      # A smaller dataframe to hold the labels for that particular image \n",
        "      image_labels = label_df[label_df['filename']==file]\n",
        "      # Adding error message for if an image doesn't have any labels\n",
        "      if len(image_labels) == 0:\n",
        "        print('Error: file ' + file + ' has no corresponding labels')\n",
        "        continue\n",
        "      # Image height\n",
        "      height = np.unique(image_labels['height'].to_numpy())[0] \n",
        "      # Image width\n",
        "      width = np.unique(image_labels['width'].to_numpy())[0] \n",
        "      # Box array: (ymin, xmin, ymax, xmax)\n",
        "      box_arr = image_labels[['ymin','xmin','ymax','xmax']].to_numpy()\n",
        "      # Normalizing boxes by width and height\n",
        "      box_arr = np.divide(box_arr, [height,width,height,width])\n",
        "      # Appending new array to box list\n",
        "      gt_boxes.append(box_arr)\n",
        "      # Getting the class integers as an array and adding to list\n",
        "      classes.append(image_labels['classInt'].to_numpy())\n",
        "    return gt_boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvj7Q0oYk75"
      },
      "source": [
        "### **Function 4:** `data_preprocess`\n",
        "Need some data preprocessing so it is formatted properly for the model:\n",
        "- Convert the class labels to one-hot representations\n",
        "- Convert everything (i.e. train images, gt boxes and class labels) to tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxoy8D0phBv3"
      },
      "source": [
        "def data_preprocess(train_images_np, gt_boxes, classes):\n",
        "    # The label_id_offset to shift classes to the zeroth index.\n",
        "    label_id_offset = 1\n",
        "    # List for image tensors\n",
        "    train_image_tensors = []\n",
        "    # lists containing the one-hot encoded classes and ground truth boxes\n",
        "    gt_classes_one_hot_tensors = []\n",
        "    gt_box_tensors = []\n",
        "    # Loop to convert the image numpy arrays, box coordinates, and classes\n",
        "    for (train_image_np, gt_box_np, class_np) in zip(train_images_np, gt_boxes, classes):\n",
        "        # convert training image to tensor, add batch dimension, and add to list\n",
        "        train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(train_image_np, dtype=tf.float32), axis=0))\n",
        "        # convert numpy array to tensor, then add to list\n",
        "        gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\n",
        "        # apply offset to have zero-indexed ground truth classes\n",
        "        zero_indexed_groundtruth_classes = tf.convert_to_tensor(class_np - label_id_offset)\n",
        "        # do one-hot encoding to ground truth classes\n",
        "        gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n",
        "    print('Done prepping data.')\n",
        "    return train_image_tensors, gt_box_tensors, gt_classes_one_hot_tensors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwAi3yImUYln"
      },
      "source": [
        "### **Function 5**: `whole_image_prep`\n",
        "This function calls to summarise functions 2 - 4 into one line of code. It loads and converts images, boxes, and classes into multiple formats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlYunaX-Rghg"
      },
      "source": [
        "def whole_image_prep(npy_dir):\n",
        "  print('Starting Image Loading:')\n",
        "  # Loading the image numpy arrays into a list and \n",
        "  images_np, files = load_npy_set(npy_dir)\n",
        "  print('Starting box coordinate and class lists:')\n",
        "  # Converting csv box coordinates and classes into numpy arrays and lists\n",
        "  gt_boxes, classes = box_lister(files)\n",
        "  print('Converting images, boxes, and classes to tensors:')\n",
        "  # Preprocessing images, boxes, and classes into (one hot) tensors \n",
        "  image_T, gt_box_T, gt_classes_OHT = data_preprocess(images_np, gt_boxes, classes)\n",
        "  return images_np, files, gt_boxes, classes, image_T, gt_box_T, gt_classes_OHT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29bU_8ysWxC3"
      },
      "source": [
        "### **Function 6**: `plot_image_sample`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBD6l-E4N71y"
      },
      "source": [
        "def plot_image_sample(images_np,gt_boxes,classes):\n",
        "    ''' Function to plot a eight images to double check box placements, etc. \n",
        "    '''\n",
        "    %matplotlib inline\n",
        "    # define the figure size\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    # using the plot_detections function to draw the ground truth boxes\n",
        "    for idx in range(8):\n",
        "        plt.subplot(2, 4, idx+1)\n",
        "        plot_detections(\n",
        "          images_np[idx],\n",
        "          gt_boxes[idx],\n",
        "          classes[idx],\n",
        "          np.ones(classes[idx].shape), # scores set to 1\n",
        "          category_index = category_index,\n",
        "        )\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdfVgnDYUgvN"
      },
      "source": [
        "## **Step 5:** Loading and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47QiXBuFGHk"
      },
      "source": [
        "# LOADING VALIDATION SET\n",
        "val_dir = '/content/drive/MyDrive/Dissertation/new_val_npy'\n",
        "# val_dir = '/content/drive/MyDrive/Dissertation/non_met_images/unanimous_npy'\n",
        "val_images_np, val_files, val_gt_boxes, val_classes, val_image_T, val_gt_box_T, val_gt_classes_OHT = whole_image_prep(val_dir)\n",
        "# 191 images in 3m 7s, then 4m 49s, then 5m 6s\n",
        "# 220 images at 960 x 640 in 2m 12s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riwqvpD5Sh85"
      },
      "source": [
        "# LOADING TEST DATA SET\n",
        "test_npy_dir = '/content/drive/MyDrive/Dissertation/new_test_npy'\n",
        "# Use the function load_image_set to load in the test set as a list of numpy arrays\n",
        "test_images_np, test_files, test_gt_boxes, test_classes, test_image_T, test_gt_box_T, test_gt_classes_OHT = whole_image_prep(test_npy_dir)\n",
        "# 190 test data only took 2m 55s to load!\n",
        "# 960 x 640: 380 images took 3m 41s to load and process!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R81aC93nYg3s"
      },
      "source": [
        "plot_image_sample(val_images_np,val_gt_boxes,val_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgG_YT7UrkJQ"
      },
      "source": [
        "## **Step 6**: Configure the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59sEM6wXheJa"
      },
      "source": [
        "# Clears old models\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# EfficientDet V1:\n",
        "# pipeline_config = '/content/drive/MyDrive/Dissertation/models_workspace/eff_det/v1/eff_det_d1_pipeline_v1_test.config'\n",
        "\n",
        "# EfficientDet V3:\n",
        "pipeline_config = '/content/drive/MyDrive/Dissertation/models_workspace/eff_det/v3/eff_det_d1_pipeline_5.config'\n",
        "\n",
        "# Load the configuration file into a dictionary\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps3AzqBvheJa"
      },
      "source": [
        "# Read in the object stored at the key 'model' of the configs dictionary\n",
        "model_config = configs['model']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfoRTeV_rkJT"
      },
      "source": [
        "# Use the model_builder build function from the config above\n",
        "detection_model = model_builder.build(model_config = model_config, is_training = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFnuT2rfheJa"
      },
      "source": [
        "## **Step 7:** Build the Model with Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkvDUUarkJg"
      },
      "source": [
        "# checkpoint_path = '/content/drive/MyDrive/Dissertation/models_workspace/eff_det/v1/ckpt-39'\n",
        "checkpoint_path = '/content/drive/MyDrive/Dissertation/models_workspace/eff_det/v3/ckpt-49'\n",
        "\n",
        "# Define a checkpoint\n",
        "checkpoint = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "\n",
        "# Restore the checkpoint to the checkpoint path\n",
        "checkpoint.restore(checkpoint_path).expect_partial()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k6oFoxTrkJi"
      },
      "source": [
        "Run a dummy image through the model so that variables are created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MANTSP9LrkJi"
      },
      "source": [
        "# use the detection model's `preprocess()` method and pass a dummy image\n",
        "tmp_image, tmp_shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
        "\n",
        "# run a prediction with the preprocessed image and shapes\n",
        "tmp_prediction_dict = detection_model.predict(tmp_image, tmp_shapes)\n",
        "\n",
        "# postprocess the predictions into final detections\n",
        "tmp_detections = detection_model.postprocess(tmp_prediction_dict, tmp_shapes)\n",
        "\n",
        "print('Weights restored!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-GIbqkzrkJ_"
      },
      "source": [
        "## **Step 8**: Define detect and IoU functions to process images\n",
        "\n",
        "Define a function that returns the detection boxes, classes, and scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aXt-bodrkKA"
      },
      "source": [
        "# Uncomment this decorator if you want to run inference eagerly\n",
        "@tf.function\n",
        "def detect(input_tensor):\n",
        "    \"\"\"Run detection on an input image.\n",
        "\n",
        "    Args:\n",
        "    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n",
        "      Note that height and width can be anything since the image will be\n",
        "      immediately resized according to the needs of the model within this\n",
        "      function.\n",
        "\n",
        "    Returns:\n",
        "    A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\n",
        "      and `detection_scores`).\n",
        "    \"\"\"\n",
        "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
        "    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
        "    # use the detection model's postprocess() method to get the the final detections\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    \n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjhC0NGndSs3"
      },
      "source": [
        "def intersection_over_union(pred_box, true_box):\n",
        "    # Split the predicted box array into separate values: (ymin, xmin, ymax, xmax)\n",
        "    ymin_pred, xmin_pred, ymax_pred, xmax_pred = np.split(pred_box, 4)\n",
        "    ymin_true, xmin_true, ymax_true, xmax_true = np.split(true_box, 4)\n",
        "\n",
        "    smoothing_factor = 1e-10\n",
        "\n",
        "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
        "    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n",
        "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
        "\n",
        "    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
        "    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
        "\n",
        "    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n",
        "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
        "    \n",
        "    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bfLjJX40moM"
      },
      "source": [
        "## **Step 9**: Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpKOWo_iPCPy"
      },
      "source": [
        "### Method 1: Finding boxes that match the ground truth\n",
        "Looks like the model is definitely outputting at least one correct bounding box per ground truth coupon, but the scores are not necessarily the highest per coupon. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Gy7LmcK7kj"
      },
      "source": [
        "# We want the boxes that have a high IoU and the same calsses as the ground truth\n",
        "\n",
        "# Run an image through the model\n",
        "i = 40\n",
        "detection_test = detect(val_image_T[i])\n",
        "gt_classes = val_classes[i]\n",
        "gt_boxes = val_gt_boxes[i]\n",
        "\n",
        "# Get predicted classes, scores, and boxes\n",
        "class_array = detection_test['detection_classes'][0].numpy().astype('int') + 1\n",
        "scores = detection_test['detection_scores'][0].numpy()\n",
        "new_boxes = detection_test['detection_boxes'][0].numpy()\n",
        "\n",
        "# Dataframe for the matched up boxes\n",
        "box_data = {'GT_BoxNum':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[0],'IoU':[0],'Scores':[0]}\n",
        "box_data = pd.DataFrame(box_data)\n",
        "\n",
        "# Iterating over the unique values in the ground truth array\n",
        "for j, gt in enumerate(gt_classes):\n",
        "  # Iterating over the predicted class values\n",
        "  for k, pc in enumerate(class_array):\n",
        "    # If the ground truth (gt) and predicted class (pc) labels are the same, find IoU\n",
        "    if gt == pc:\n",
        "      pred_box = new_boxes[k]\n",
        "      true_box = gt_boxes[j]\n",
        "      iou = np.round(intersection_over_union(pred_box, true_box),decimals=3)\n",
        "      # If the boxes intersect, add to the dataframe\n",
        "      if iou > 0.7:\n",
        "        box_data = box_data.append({'GT_BoxNum':j, 'Pred_BoxNum':k,\n",
        "                                    'GT_Class':gt_classes[j], 'Pred_Class':class_array[k],\n",
        "                                    'IoU': iou, 'Scores':scores[k]}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "box_data = box_data.drop([0])\n",
        "# Sort by ground truth box number\n",
        "box_data = box_data.sort_values(['GT_BoxNum','Scores'], ascending = [1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi1wtvWyQjKh"
      },
      "source": [
        "box_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpdiy9BWOimZ"
      },
      "source": [
        "box_data['Pred_BoxNum'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuwRvzAQEzd"
      },
      "source": [
        "### Method 2: Finding the breakdown of scores for each ground truth coupon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMD4NbnlRgCW"
      },
      "source": [
        "np.round(intersection_over_union(pred_box, true_box),decimals=3)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMX-eNRCQV8d"
      },
      "source": [
        "# We want to find all the boxes that have a high IoU with the ground truth\n",
        "\n",
        "# Run an image through the model\n",
        "i = 70\n",
        "detection_test = detect(val_image_T[i])\n",
        "gt_classes = val_classes[i]\n",
        "gt_boxes = val_gt_boxes[i]\n",
        "\n",
        "# Get predicted classes, scores, and boxes\n",
        "class_array = detection_test['detection_classes'][0].numpy().astype('int') + 1\n",
        "scores = detection_test['detection_scores'][0].numpy()\n",
        "new_boxes = detection_test['detection_boxes'][0].numpy()\n",
        "\n",
        "# Dataframe for the matched up boxes\n",
        "box_data = {'GT_BoxNum':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[0],'IoU':[0],'Scores':[0]}\n",
        "box_data = pd.DataFrame(box_data)\n",
        "\n",
        "# Iterating over the unique values in the ground truth array\n",
        "for j, true_box in enumerate(gt_boxes):\n",
        "  # Iterating over the predicted class values\n",
        "  for k, pred_box in enumerate(new_boxes):\n",
        "    # Calculate the IoU for these two boxes\n",
        "    iou = np.round(intersection_over_union(pred_box, true_box),decimals=3)[0]\n",
        "    # If the IoU is high and the scores are above a certain threshold, add info to the dataframe\n",
        "    if (iou > 0.8) and (scores[k] > 0.1):\n",
        "      box_data = box_data.append({'GT_BoxNum':j, 'Pred_BoxNum':k,\n",
        "                                  'GT_Class':gt_classes[j], 'Pred_Class':class_array[k],\n",
        "                                  'IoU': iou, 'Scores':scores[k]}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "box_data = box_data.drop([0])\n",
        "# Sort by ground truth box number\n",
        "box_data = box_data.sort_values(['GT_BoxNum','Scores'], ascending = [1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU8obGqGRDde"
      },
      "source": [
        "box_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWK2GfENUgVJ"
      },
      "source": [
        "### Method 3: Getting the percentage of the highest scoring predictions that are correct for each ground truth coupon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZqR51ARUt-2"
      },
      "source": [
        "def find_max_scores_for_gt(i,val_image_T,val_classes,val_gt_boxes):\n",
        "  # Get the ground truth classes and boxes for this image\n",
        "  gt_classes = val_classes[i]\n",
        "  gt_boxes = val_gt_boxes[i]\n",
        "  # Run the image through the model\n",
        "  detection_test = detect(val_image_T[i])\n",
        "\n",
        "  # Get predicted classes, scores, and boxes\n",
        "  class_array = detection_test['detection_classes'][0].numpy().astype('int') + 1\n",
        "  scores = detection_test['detection_scores'][0].numpy()\n",
        "  new_boxes = detection_test['detection_boxes'][0].numpy()\n",
        "\n",
        "  # Dataframe for the matched up boxes\n",
        "  box_data = {'GT_BoxNum':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[0],'IoU':[0],'Scores':[0]}\n",
        "  box_data = pd.DataFrame(box_data)\n",
        "\n",
        "  # Iterating over the unique values in the ground truth array\n",
        "  for j, true_box in enumerate(gt_boxes):\n",
        "    # Iterating over the predicted class values\n",
        "    for k, pred_box in enumerate(new_boxes):\n",
        "      # Calculate the IoU for these two boxes\n",
        "      iou = np.round(intersection_over_union(pred_box, true_box),decimals=3)[0]\n",
        "      # If the IoU is high and the scores are above a certain threshold, add info to the dataframe\n",
        "      if (iou > 0.6) and (scores[k] > 0.1):\n",
        "        box_data = box_data.append({'GT_BoxNum':j, 'Pred_BoxNum':k,\n",
        "                                    'GT_Class':gt_classes[j], 'Pred_Class':class_array[k],\n",
        "                                    'IoU': iou, 'Scores':scores[k]}, ignore_index=True)\n",
        "\n",
        "  # Drop the row of all zeros from box_data\n",
        "  box_data = box_data.drop([0])\n",
        "  # Sort by ground truth box number\n",
        "  box_data = box_data.sort_values(['GT_BoxNum','Scores'], ascending = [1,0])\n",
        "\n",
        "  # If there aren't any overlapping boxes, output an empty max dataframe\n",
        "  if box_data.shape[0] == 0: \n",
        "    max_vals = pd.DataFrame({'GT_BoxNum':[0],'Scores':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[1],'IoU':[0]})\n",
        "    max_vals = max_vals.drop([0])\n",
        "    print('Image ' + str(i) + ' did not have any suitable predictions')\n",
        "  # Otherwise find the maximum values per box\n",
        "  else:\n",
        "    # Finding the max score for each GT box\n",
        "    max_vals = (box_data >>\n",
        "      group_by(X.GT_BoxNum) >>\n",
        "      summarize(Scores = X.Scores.max()))\n",
        "    # Merging with the full dataset to get all of the info\n",
        "    max_vals = max_vals.merge(box_data, on=['GT_BoxNum','Scores'], how='left')\n",
        "    \n",
        "  return detection_test, max_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAyOWgCCagVG"
      },
      "source": [
        "# Iterating over the full validation set\n",
        "cor_data = {'FileNum':[0],'Correct':[0],'NumGT':[0],'NumPred':[0]}\n",
        "cor_data = pd.DataFrame(cor_data)\n",
        "for i in range(len(val_classes)):\n",
        "  detection_test, max_vals = find_max_scores_for_gt(i,val_image_T,val_classes,val_gt_boxes)\n",
        "  # We divide by val_classes[i].shape[0] because that's the number of ground truth boxes\n",
        "  cor_num = sum(max_vals['GT_Class'] == max_vals['Pred_Class'])/val_classes[i].shape[0]\n",
        "  # ^ There may be coupons that don't receive a prediction from this output\n",
        "  cor_data = cor_data.append({'FileNum':i, 'Correct':cor_num,\n",
        "                              'NumGT':val_classes[i].shape[0],\n",
        "                              'NumPred':max_vals.shape[0]}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "cor_data = cor_data.drop([0])\n",
        "# Turn data into percentages\n",
        "cor_data['Correct'] = np.round(cor_data['Correct']*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UUcmj3_1U5X"
      },
      "source": [
        "cor_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNw-l9KforV2"
      },
      "source": [
        "cor_data[cor_data['NumGT'] != cor_data['NumPred']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrmnt2FcWYh"
      },
      "source": [
        "mean(cor_data['Correct'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms4CzPq_ffCj"
      },
      "source": [
        "for i in np.unique(cor_data['Correct']):\n",
        "  count = sum(cor_data['Correct'] == i)\n",
        "  print(str(i) + ': ' + str(count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfT3Nsq7q7_J"
      },
      "source": [
        "sum(cor_data['Correct'] < 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XrKeDt1pjGC"
      },
      "source": [
        "### Iterating Over Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWz9LZbxpk0b"
      },
      "source": [
        "# Iterating over the full validation set\n",
        "cor_test = {'FileNum':[0],'Correct':[0],'NumGT':[0],'NumPred':[0]}\n",
        "cor_test = pd.DataFrame(cor_test)\n",
        "for i in range(len(test_classes)):\n",
        "  detection_test, max_vals = find_max_scores_for_gt(i,test_image_T,test_classes,test_gt_boxes)\n",
        "  # We divide by val_classes[i].shape[0] because that's the number of ground truth boxes\n",
        "  cor_num = sum(max_vals['GT_Class'] == max_vals['Pred_Class'])/test_classes[i].shape[0]\n",
        "  # ^ There may be coupons that don't receive a prediction from this output\n",
        "  cor_test = cor_test.append({'FileNum':i, 'Correct':cor_num,\n",
        "                              'NumGT':test_classes[i].shape[0],\n",
        "                              'NumPred':max_vals.shape[0]}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "cor_test = cor_test.drop([0])\n",
        "# Turn data into percentages\n",
        "cor_test['Correct'] = np.round(cor_test['Correct']*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yeqmAvap-OH"
      },
      "source": [
        "cor_test[cor_test['NumGT'] != cor_test['NumPred']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDR_YFueqRDx"
      },
      "source": [
        "mean(cor_test['Correct'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEMkNoqsqb0C"
      },
      "source": [
        "for i in np.unique(cor_test['Correct']):\n",
        "  count = sum(cor_test['Correct'] == i)\n",
        "  print(str(i) + ': ' + str(count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11CC_P4XrObV"
      },
      "source": [
        "sum(cor_test['Correct'] < 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCpSM-_nkvH4"
      },
      "source": [
        "### Method 4: Displaying images with the Exceptions in EfficientDet V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQt0M3XRlFhz"
      },
      "source": [
        "'''\n",
        "# For validation\n",
        "exceptions = cor_data[cor_data['Correct'] < 100]\n",
        "exc_list = exceptions['FileNum'].to_numpy().astype('int')\n",
        "exceptions\n",
        "'''\n",
        "# For testing\n",
        "exceptions = cor_test[cor_test['Correct'] < 100]\n",
        "exc_list = exceptions['FileNum'].to_numpy().astype('int')\n",
        "exceptions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm-QfhKKu614"
      },
      "source": [
        "exceptions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZoXMacvvc5"
      },
      "source": [
        "#### Code for the Test Set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23nJiIPvvIY"
      },
      "source": [
        "# For Validation - Outputting the Summarised Predictions \n",
        "i = exc_list[18]\n",
        "# Get the predictions for this exception image\n",
        "detection_test, max_vals = find_max_scores_for_gt(i,test_image_T,test_classes,test_gt_boxes)\n",
        "# The index numbers of the predicted boxes we want to use\n",
        "pred_nums = max_vals['Pred_BoxNum'].to_numpy().astype('int')\n",
        "\n",
        "# Adding one to the array of predicted classes to get 1-9 classes\n",
        "class_array = detection_test['detection_classes'][0].numpy().astype(np.uint32) + 1\n",
        "class_array = class_array[pred_nums]\n",
        "det_boxes = detection_test['detection_boxes'][0].numpy()[pred_nums]\n",
        "det_scores = detection_test['detection_scores'][0].numpy()[pred_nums]\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "input_tensor = val_image_T[i]\n",
        "# define the figure size\n",
        "plt.figure(figsize=(80, 50))\n",
        "# using the plot_detections function to draw the ground truth boxes\n",
        "plot_detections(\n",
        "    test_images_np[i],\n",
        "    det_boxes,\n",
        "    class_array,\n",
        "    det_scores,\n",
        "    category_index = category_index,\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISqpACwQxNJp"
      },
      "source": [
        "# Plotting the Ground Truth Values for a particular test\n",
        "i = exc_list[18]\n",
        "\n",
        "%matplotlib inline\n",
        "# define the figure size\n",
        "plt.figure(figsize=(80, 50))\n",
        "plot_detections(\n",
        "    test_images_np[i],\n",
        "    test_gt_boxes[i],\n",
        "    test_classes[i],\n",
        "    np.ones(test_classes[i].shape), # scores set to 1\n",
        "    category_index = category_index,\n",
        "    )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXFoJa6fvrFN"
      },
      "source": [
        "#### Code for the Validation Set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GA4MNbclPOX"
      },
      "source": [
        "# For Validation - Outputting the Summarised Predictions \n",
        "i = 7 # i = exc_list[0]\n",
        "# Get the predictions for this exception image\n",
        "detection_test, max_vals = find_max_scores_for_gt(i,val_image_T,val_classes,val_gt_boxes)\n",
        "# The index numbers of the predicted boxes we want to use\n",
        "pred_nums = max_vals['Pred_BoxNum'].to_numpy().astype('int')\n",
        "\n",
        "# Adding one to the array of predicted classes to get 1-9 classes\n",
        "class_array = detection_test['detection_classes'][0].numpy().astype(np.uint32) + 1\n",
        "class_array = class_array[pred_nums]\n",
        "det_boxes = detection_test['detection_boxes'][0].numpy()[pred_nums]\n",
        "det_scores = detection_test['detection_scores'][0].numpy()[pred_nums]\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "input_tensor = val_image_T[i]\n",
        "# define the figure size\n",
        "plt.figure(figsize=(80, 50))\n",
        "# using the plot_detections function to draw the ground truth boxes\n",
        "plot_detections(\n",
        "    val_images_np[i],\n",
        "    det_boxes,\n",
        "    class_array,\n",
        "    det_scores,\n",
        "    category_index = category_index,\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tviZ4n4GvKSO"
      },
      "source": [
        "# Plotting the Ground Truth Values for a particular test\n",
        "i = exc_list[42]\n",
        "\n",
        "%matplotlib inline\n",
        "# define the figure size\n",
        "plt.figure(figsize=(80, 50))\n",
        "plot_detections(\n",
        "    val_images_np[i],\n",
        "    val_gt_boxes[i],\n",
        "    val_classes[i],\n",
        "    np.ones(val_classes[i].shape), # scores set to 1\n",
        "    category_index = category_index,\n",
        "    )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjKjvhINrNHH"
      },
      "source": [
        "i = exc_list[5]\n",
        "\n",
        "%matplotlib inline\n",
        "# define the figure size\n",
        "plt.figure(figsize=(80, 50))\n",
        "plot_detections(\n",
        "    val_images_np[i],\n",
        "    detection_test['detection_boxes'][0].numpy(),\n",
        "    detection_test['detection_classes'][0].numpy().astype(np.uint32) + 1,\n",
        "    detection_test['detection_scores'][0].numpy(), # scores set to 1\n",
        "    category_index = category_index,\n",
        "    )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfXEobZsJjt"
      },
      "source": [
        "detection_test['detection_classes'][0].numpy().astype(np.uint32) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTf_wcqXk2mX"
      },
      "source": [
        "# Iterating over the full validation set\n",
        "cor_data = {'FileNum':[0],'Correct':[0]}\n",
        "cor_data = pd.DataFrame(cor_data)\n",
        "for i in range(len(val_classes)):\n",
        "  max_vals = find_max_scores_for_gt(i,val_image_T,val_classes,val_gt_boxes)\n",
        "  cor_num = sum(max_vals['GT_Class'] == max_vals['Pred_Class'])/max_vals.shape[0]\n",
        "  cor_data = cor_data.append({'FileNum':i, 'Correct':cor_num}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "cor_data = cor_data.drop([0])\n",
        "# Turn data into percentages\n",
        "cor_data['Correct'] = np.round(cor_data['Correct']*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvp03z60z1wv"
      },
      "source": [
        "### Method 5: Getting a contingency table for overall P/T/U classifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqqSgFunz5fw"
      },
      "source": [
        "def find_overall_class_pred(i,val_image_T,val_classes,val_gt_boxes):\n",
        "  # Get the ground truth classes and boxes for this image\n",
        "  gt_classes = val_classes[i]\n",
        "  gt_boxes = val_gt_boxes[i]\n",
        "  # Run the image through the model\n",
        "  detection_test = detect(val_image_T[i])\n",
        "\n",
        "  # Get predicted classes, scores, and boxes\n",
        "  class_array = detection_test['detection_classes'][0].numpy().astype('int') + 1\n",
        "  scores = detection_test['detection_scores'][0].numpy()\n",
        "  new_boxes = detection_test['detection_boxes'][0].numpy()\n",
        "\n",
        "  # Dataframe for the matched up boxes\n",
        "  box_data = {'GT_BoxNum':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[0],'IoU':[0],'Scores':[0]}\n",
        "  box_data = pd.DataFrame(box_data)\n",
        "\n",
        "  # Iterating over the unique values in the ground truth array\n",
        "  for j, true_box in enumerate(gt_boxes):\n",
        "    # Iterating over the predicted class values\n",
        "    for k, pred_box in enumerate(new_boxes):\n",
        "      # Calculate the IoU for these two boxes\n",
        "      iou = np.round(intersection_over_union(pred_box, true_box),decimals=3)[0]\n",
        "      # If the IoU is high and the scores are above a certain threshold, add info to the dataframe\n",
        "      if (iou > 0.6) and (scores[k] > 0.1):\n",
        "        box_data = box_data.append({'GT_BoxNum':j, 'Pred_BoxNum':k,\n",
        "                                    'GT_Class':gt_classes[j], 'Pred_Class':class_array[k],\n",
        "                                    'IoU': iou, 'Scores':scores[k]}, ignore_index=True)\n",
        "\n",
        "  # Drop the row of all zeros from box_data\n",
        "  box_data = box_data.drop([0])\n",
        "  # Sort by ground truth box number\n",
        "  box_data = box_data.sort_values(['GT_BoxNum','Scores'], ascending = [1,0])\n",
        "\n",
        "  # If there aren't any overlapping boxes, output an empty max dataframe\n",
        "  if box_data.shape[0] == 0: \n",
        "    max_vals = pd.DataFrame({'GT_BoxNum':[0],'Scores':[0],'Pred_BoxNum':[0],'GT_Class':[0],'Pred_Class':[1],'IoU':[0]})\n",
        "    max_vals = max_vals.drop([0])\n",
        "    print('Image ' + str(i) + ' did not have any suitable predictions')\n",
        "  # Otherwise find the maximum values per box\n",
        "  else:\n",
        "    # Finding the max score for each GT box\n",
        "    max_vals = (box_data >>\n",
        "      group_by(X.GT_BoxNum) >>\n",
        "      summarize(Scores = X.Scores.max()))\n",
        "    # Merging with the full dataset to get all of the info\n",
        "    max_vals = max_vals.merge(box_data, on=['GT_BoxNum','Scores'], how='left')\n",
        "  \n",
        "  # - - - Adding a section to find the overall P/T/U ratings for the GT and Predicted Classes - - - \n",
        "\n",
        "  # A dictionary to convert class integers to P/T/U ratings\n",
        "  reverse_dict = {1:'P', 2:'T', 3:'U', 4:'P', 5:'T', 6:'U', 7:'P', 8:'T', 9:'U'}\n",
        "  # Mapping classes for ground truth and predicted classes\n",
        "  max_vals['GT_OC'] = max_vals['GT_Class'].map(reverse_dict)\n",
        "  max_vals['Pred_OC'] = max_vals['Pred_Class'].map(reverse_dict)\n",
        "  # Getting the maximum value, which happens to be the worst potential corrosion level P < T < U\n",
        "  GT_OC = max(max_vals['GT_OC'])\n",
        "  Pred_OC = max(max_vals['Pred_OC'])\n",
        "  \n",
        "  return GT_OC, Pred_OC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnpEUpfOgdGH"
      },
      "source": [
        "Code for test classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVaYIoM2gMw"
      },
      "source": [
        "# Create a dataframe for the overall classes\n",
        "dataO = {'FileNum':[0],'GT_OC':[0],'Pred_OC':[0]}\n",
        "dataO = pd.DataFrame(dataO)\n",
        "# Iterate over the test set\n",
        "for i in range(len(test_classes)):\n",
        "  GT_OC, Pred_OC = find_overall_class_pred(i,test_image_T,test_classes,test_gt_boxes)\n",
        "  # Add overall classes to the dataframe\n",
        "  dataO = dataO.append({'FileNum':i, 'GT_OC':GT_OC,'Pred_OC':Pred_OC}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "dataO = dataO.drop([0])\n",
        "\n",
        "# Get contingency table for the classes\n",
        "data_crosstab = pd.crosstab(dataO['GT_OC'],\n",
        "                            dataO['Pred_OC'], \n",
        "                               margins = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv9MdhBc6isD"
      },
      "source": [
        "data_crosstab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VoIOcKCgfPm"
      },
      "source": [
        "Code for validation classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsmB44Su7s7v"
      },
      "source": [
        "# Create a dataframe for the overall classes\n",
        "dataO = {'FileNum':[0],'GT_OC':[0],'Pred_OC':[0]}\n",
        "dataO = pd.DataFrame(dataO)\n",
        "# Iterate over the test set\n",
        "for i in range(len(val_classes)): \n",
        "  GT_OC, Pred_OC = find_overall_class_pred(i,val_image_T,val_classes,val_gt_boxes)\n",
        "  # Add overall classes to the dataframe\n",
        "  dataO = dataO.append({'FileNum':i, 'GT_OC':GT_OC,'Pred_OC':Pred_OC}, ignore_index=True)\n",
        "\n",
        "# Drop the row of all zeros from box_data\n",
        "dataO = dataO.drop([0])\n",
        "\n",
        "# Get contingency table for the classes\n",
        "data_crosstab = pd.crosstab(dataO['GT_OC'],\n",
        "                            dataO['Pred_OC'], \n",
        "                               margins = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f39p_q_5V3O"
      },
      "source": [
        "dataO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzXFn1U05Zky"
      },
      "source": [
        "### Method 6: Getting contingency tables for class-specific classifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIK765fT5ehQ"
      },
      "source": [
        "def find_class_pred(image_T,classes,gt_boxes):\n",
        "  # Start a dataframe for the contingency table data\n",
        "  con_data = {'FileNum':[0],'GT_Class':[0],'Pred_Class':[0]}\n",
        "  con_data = pd.DataFrame(con_data)\n",
        "  # Iterating over the full image set\n",
        "  for i in range(len(classes)): # \n",
        "    # Get the bounding box predictions\n",
        "    detection_test, max_vals = find_max_scores_for_gt(i,image_T,classes,gt_boxes)\n",
        "    # We divide by val_classes[i].shape[0] because that's the number of ground truth boxes\n",
        "    predictions = max_vals[['GT_Class','Pred_Class']]\n",
        "    for j in range(predictions.shape[0]):\n",
        "      # ^ There may be coupons that don't receive a prediction from this output\n",
        "      con_data = con_data.append({'FileNum':i, 'GT_Class': predictions['GT_Class'][j],\n",
        "                                  'Pred_Class':predictions['Pred_Class'][j]}, ignore_index=True)\n",
        "\n",
        "  # Drop the row of all zeros from box_data\n",
        "  con_data = con_data.drop([0])\n",
        "\n",
        "  # A dictionary to convert class integers to P/T/U ratings\n",
        "  reverse_dict = {1:'Ag-P', 2:'Ag-T', 3:'Ag-U', 4:'Cu-P', 5:'Cu-T', 6:'Cu-U', 7:'Pb-P', 8:'Pb-T', 9:'Pb-U'}\n",
        "  # Mapping classes for ground truth and predicted classes\n",
        "  con_data['GT_OC'] = con_data['GT_Class'].map(reverse_dict)\n",
        "  con_data['Pred_OC'] = con_data['Pred_Class'].map(reverse_dict)\n",
        "\n",
        "  # Get contingency table for the classes\n",
        "  data_crosstab = pd.crosstab(con_data['GT_OC'], con_data['Pred_OC'], margins = False)\n",
        "\n",
        "  return data_crosstab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18lJG0OP7mx3"
      },
      "source": [
        "val_con = find_class_pred(val_image_T,val_classes,val_gt_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4b27a_n79Ma"
      },
      "source": [
        "val_con"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Zo7ScU9sNu"
      },
      "source": [
        "test_con = find_class_pred(test_image_T,test_classes,test_gt_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hojmI7jA-Kgy"
      },
      "source": [
        "test_con"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inmbQejmqaF7"
      },
      "source": [
        "test_con['Ag-P'][0] + test_con['Ag-T'][1] + test_con['Ag-U'][2] + test_con['Cu-P'][3] + test_con['Cu-T'][4] + test_con['Cu-U'][5] + test_con['Pb-P'][6] + test_con['Pb-T'][7] + test_con['Pb-U'][8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC5J3EcqrLdV"
      },
      "source": [
        "test_npy = test_con.to_numpy()\n",
        "test_total = sum(sum(test_npy))\n",
        "error_count = sum(test_npy[test_npy < 10])\n",
        "error_p = error_count / test_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqlXmiQBrTgG"
      },
      "source": [
        "error_p"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}