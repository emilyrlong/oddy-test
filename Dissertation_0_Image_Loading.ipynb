{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Dissertation 0: Image Loading",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyrlong/oddy-test/blob/main/Dissertation_0_Image_Loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Dissertation Step 0: Image Loading\n",
        "\n",
        "This Colab will load jpg images and export them as numpy arrays to see if we can speed up the training process for future models that identify corrosion from Oddy Tests. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## **Step 1**: Install Tensorflow and Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxXN6EYMKFZ"
      },
      "source": [
        "# !pip install tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMNX7lKR0fk1"
      },
      "source": [
        "#!pip install tensorflow-gpu\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m35sE9VxMfbf"
      },
      "source": [
        "# Connect colab to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "## **Step 2**: Import Packages\n",
        "\n",
        "Let's now import the packages you will use in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogyryF2lFBL"
      },
      "source": [
        "## **Step 3**: Function Converting Image to Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y9R0Xllefec"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Shape: (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args: path - a file path.\n",
        "    Returns: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    \n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data))\n",
        "    (im_width, im_height) = image.size\n",
        "    \n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyzSGUDsrkI7"
      },
      "source": [
        "## **Step 4**: Function to Load Folder of Images\n",
        "\n",
        "Get a set of images from the Google Drive folder and their file names. The images are quite large, so the step which converts them into numpy arrays will take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0m3IESntTsu"
      },
      "source": [
        "# A FUNCTION FOR LOADING IMAGES\n",
        "def load_image_set(image_dir, new_dir):\n",
        "    \"\"\"Load a folder of images, convert to numpy arrays, and save in new folder.\n",
        "    Args: \n",
        "      image_dir - a path to folder of training, validation, or test images. \n",
        "      new_dir - a path to the folder for numpy arrays\n",
        "    \"\"\"\n",
        "    # Get a list of the files in the image folder\n",
        "    files = os.listdir(image_dir)\n",
        "    # Iterate and load each image in the file\n",
        "    for file in files:\n",
        "        # define the path (string) for each image\n",
        "        image_path = os.path.join(image_dir,file)\n",
        "        print(image_path)\n",
        "        # load images into numpy arrays\n",
        "        train_img_np = load_image_into_numpy_array(image_path)\n",
        "        # Assign a new path to save the image's numpy array file\n",
        "        new_path = os.path.join(new_dir,file.replace('jpg','npy'))\n",
        "        # Save the new file\n",
        "        np.save(new_path, train_img_np)\n",
        "    print('Done Loading and Saving!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol6rNftu7XSF"
      },
      "source": [
        "## **Step 5**: Loading training, validation, and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHUmJoRByvZU"
      },
      "source": [
        "# print(time.perf_counter())\n",
        "# path of the directory containing the images\n",
        "image_dir = '/content/drive/MyDrive/Dissertation/non_met_images/non-met-unanimous'\n",
        "# path of the new directory to hold the npy files\n",
        "npy_dir = '/content/drive/MyDrive/Dissertation/non_met_images/unanimous_npy'\n",
        "# Use the function load_image_set to load in the test set as a list of numpy arrays\n",
        "load_image_set(image_dir, npy_dir)\n",
        "# print(time.perf_counter()) \n",
        "\n",
        "# Old: ~3 mins for 5 images (6000 x 4000 images)\n",
        "# New: 12 seconds for 5 images (1536 x 1024 images)\n",
        "# Test Set: 191 images in 8m 34s\n",
        "# Val Set: 191 images in 7m 52s\n",
        "# Training Set (1/3): 510 images in 23m 38s\n",
        "# Training Set (2/3): 510 images in 21m 11s\n",
        "# Training Set (3/3): 508 images in 21m 23s\n",
        "# Training Set (1/4) - 960 x 640: 510 images in 13m 46s\n",
        "# Training Set (2/4) - 960 x 640: 510 images in 14m 34s\n",
        "# Training Set (3/4) - 960 x 640: 508 images in 13m 53s\n",
        "# Training Set (4/4) - 960 x 640: 180 images in \n",
        "# Test Set - Batch 3 - 960 x 640: 88 images in 2m 3s (191 images - 3m 47s)\n",
        "# Val Set  - Batch 3 - 960 x 640: 30 images in 41s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p2G899n7k8P"
      },
      "source": [
        "## **Step 6:** Double checking the .npy files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUGPnwx7zhuj"
      },
      "source": [
        "npy_dir = '/content/drive/MyDrive/Dissertation/new_test_npy'\n",
        "files = os.listdir(npy_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O4vtY84zkdR"
      },
      "source": [
        "len(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvgAlLvXtHlt"
      },
      "source": [
        "a = pd.DataFrame(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFymnjwstMfg"
      },
      "source": [
        "a.to_csv('/content/drive/MyDrive/Dissertation/labels/test_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqjKPCD-1sUE"
      },
      "source": [
        "print(time.perf_counter())\n",
        "\n",
        "npy_dir = '/content/drive/MyDrive/Dissertation/val_npy'\n",
        "files = os.listdir(npy_dir)\n",
        "\n",
        "images_np = []\n",
        "for file in files:\n",
        "  npy_path = os.path.join(npy_dir,file)\n",
        "  print(npy_path)\n",
        "  test_img = np.load(npy_path)\n",
        "  images_np.append(test_img)\n",
        "\n",
        "print(time.perf_counter()) \n",
        "\n",
        "# Less than a second!!\n",
        "# Test Set: 1 second!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdHJZaVZ7evr"
      },
      "source": [
        "Double checking that the images look good:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEHQgRa_9iRz"
      },
      "source": [
        "# configure plot settings via rcParams\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.rcParams['xtick.labelsize'] = False\n",
        "plt.rcParams['ytick.labelsize'] = False\n",
        "plt.rcParams['xtick.top'] = False\n",
        "plt.rcParams['xtick.bottom'] = False\n",
        "plt.rcParams['ytick.left'] = False\n",
        "plt.rcParams['ytick.right'] = False\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\n",
        "\n",
        "# plot images\n",
        "for idx, image_np in enumerate(images_np[20:26]):\n",
        "    plt.subplot(2, 3, idx+1)\n",
        "    plt.imshow(image_np)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}